{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2387a70f-1a88-47bf-8e58-9b9dd1266f4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import re \n",
    "from urllib.request import urlopen\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup \n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "from itertools import permutations\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\")\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "import optuna.integration.lightgbm as lgb_o\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "983ae5fc-7f94-483c-b006-cd6fe2eec5b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#閾値設定\n",
    "def gain(return_func, X, n_samples=100, range_=[0.5, 3.5]):\n",
    "    gain = {}\n",
    "    for i in tqdm(range(n_samples)):\n",
    "        threshold = range_[1] * i / n_samples + range_[0] * (1 - (i / n_samples))\n",
    "        n_bets, return_rate, n_hits, std = return_func(X, threshold)\n",
    "        if n_bets > 2:\n",
    "            gain[threshold] = {\"return_rate\":return_rate,\n",
    "                                \"n_hits\":n_hits,\n",
    "                                \"std\":std,\n",
    "                                \"n_bets\":n_bets}\n",
    "    return pd.DataFrame(gain).T\n",
    "\n",
    "#入力年のrace_id_listの制作\n",
    "def race_id_c(year):\n",
    "    race_id_list = []\n",
    "    \n",
    "    race_id_head = year\n",
    "    for place in range(1,11,1):\n",
    "        for kai in range(1,6,1):\n",
    "            for day in range(1,13,1):\n",
    "                for r in range(1,13,1):\n",
    "                    race_id = str(place).zfill(2) + str(kai).zfill(2) +\\\n",
    "                    str(day).zfill(2) + str(r).zfill(2)\n",
    "                    race_ids = race_id_head + race_id\n",
    "                    race_id_list.append(race_ids)\n",
    "    return race_id_list\n",
    "\n",
    "#時系列を元にデータ分割\n",
    "def split_data(df, test_size=0.3):\n",
    "    sorted_id_list = df.sort_values(\"date\").index.unique()\n",
    "    train_id_list = sorted_id_list[: round(len(sorted_id_list) * (1 - test_size))]\n",
    "    test_id_list = sorted_id_list[round(len(sorted_id_list) * (1 - test_size)) :]\n",
    "    train = df.loc[train_id_list]#.drop(['date'], axis=1)\n",
    "    test = df.loc[test_id_list]#.drop(['date'], axis=1)\n",
    "    return train, test\n",
    "\n",
    "def plot(df, label=' '):\n",
    "    plt.fill_between(df.index, y1=df['return_rate']-df['std'],\n",
    "        y2=df['return_rate']+df['std'],alpha=0.3)\n",
    " \n",
    "    plt.plot(df.index, df['return_rate'], label=label)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "place_dict = {\n",
    "    '札幌':'01',  '函館':'02',  '福島':'03',  '新潟':'04',  '東京':'05', \n",
    "    '中山':'06',  '中京':'07',  '京都':'08',  '阪神':'09',  '小倉':'10'\n",
    "}\n",
    "\n",
    "race_type_dict = {\n",
    "    '芝': '芝', 'ダ': 'ダート', '障': '障害'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc84fa47-a1aa-44dc-bced-b2983c8e6a3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "horse_results = pd.read_pickle(\"pickle_file/horse_results_21.pickle\")\n",
    "peds_data = pd.read_pickle(\"pickle_file/n_peds_all2.pickle\")\n",
    "results_data = pd.read_pickle('pickle_file/results_all.pickle')\n",
    "return_tables = pd.read_pickle('pickle_file/Return_tables_all.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5725d0cd-3792-417c-9f40-35ddd244e4e5",
   "metadata": {},
   "source": [
    "dataprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "08ef4602-b52f-4663-90ca-e86cf49a5476",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class DataProcessor:\n",
    "    def __init__(self):\n",
    "        self.data = pd.DataFrame() # raw data\n",
    "        self.data_p = pd.DataFrame() #after preprocessing\n",
    "        self.data_h = pd.DataFrame() #after merging horse_results\n",
    "        self.data_pe = pd.DataFrame() #after merging peds\n",
    "        self.data_c = pd.DataFrame() #after processing categorical features\n",
    "        self.data_ = pd.DataFrame()\n",
    "        #self.no_peds = pd.DataFrame()#親データがないhorse_id_list\n",
    "    \n",
    "    # 馬の過去成績のデータ追加    \n",
    "    def merge_horse_results(self, hr, n_samples_list=[5, 9, 'all']):\n",
    "        self.data_h = self.data_p.copy()\n",
    "        for n_samples in n_samples_list:\n",
    "            self.data_h = hr.merge_all(self.data_h, n_samples=n_samples)\n",
    "            \n",
    "        #self.data_h[\"interval\"] = (self.data_h[\"data\"] - self.data_h[\"latest\"]).dt.days\n",
    "        self.data_h.drop([\"開催\"],axis=1, inplace=True)\n",
    "    \n",
    "    # 馬の親データの追加                \n",
    "    def merge_peds(self, peds):\n",
    "        self.data_pe = self.data_h.merge(peds,left_on='horse_id',\n",
    "        right_index=True, how='left')\n",
    "        \n",
    "        self.no_peds = self.data_pe[self.data_pe['peds_0'].isnull()]\\\n",
    "            ['horse_id'].unique()\n",
    "        if len(self.no_peds) > 0:\n",
    "            print('scrape peds at horse_id_list \"no_peds\"')\n",
    "    \n",
    "    # 質的変数への変換        \n",
    "    def process_categorical(self, le_horse, le_jockey, results_m):\n",
    "        df = self.data_pe.copy()\n",
    "        \n",
    "        #ラベルエンコーディング　horse_id,jockey_idを0始まりの整数に変換\n",
    "        mask_horse = df['horse_id'].isin(le_horse.classes_)\n",
    "        new_horse_id = df['horse_id'].mask(mask_horse).dropna().unique()\n",
    "        le_horse.classes_ = np.concatenate([le_horse.classes_, new_horse_id])\n",
    "        df['horse_id'] = le_horse.transform(df['horse_id'])\n",
    "        \n",
    "        mask_jockey = df['jockey_id'].isin(le_jockey.classes_)\n",
    "        new_jockey_id = df['jockey_id'].mask(mask_jockey).dropna().unique()\n",
    "        le_jockey.classes_ = np.concatenate([le_jockey.classes_, new_jockey_id])\n",
    "        df['jockey_id'] = le_jockey.transform(df['jockey_id'])\n",
    "        \n",
    "        df[\"horse_id\"] = df[\"horse_id\"].astype('category')\n",
    "        df[\"jockey_id\"] = df[\"jockey_id\"].astype('category')\n",
    "        \n",
    "        weathers = results_m['weather'].unique()\n",
    "        race_types = results_m['race_type'].unique()\n",
    "        ground_states = results_m['ground_state'].unique()\n",
    "        sexes = results_m['性'].unique()\n",
    "        df['weather'] = pd.Categorical(df['weather'], weathers)\n",
    "        df['race_type'] = pd.Categorical(df['race_type'], race_types)\n",
    "        df['ground_state'] = pd.Categorical(df['ground_state'], ground_states)\n",
    "        df['性'] = pd.Categorical(df['性'], sexes)\n",
    "        \n",
    "        df = pd.get_dummies(df, columns=['weather', 'race_type', 'ground_state', '性'])\n",
    "        #race_idを軸に馬番をsort\n",
    "        df = df.reset_index().sort_values([\"index\",\"馬番\"]).set_index('index')\n",
    "        df.index.name = None\n",
    "        \n",
    "        self.data_c = df\n",
    "     \n",
    "    \n",
    "# Results class \n",
    "# 足りないhorse_idをスクレイプした際は確認したのちdef to_data_frameを使う必要あり\n",
    "class Results(DataProcessor):\n",
    "    def __init__(self, results):\n",
    "        super(Results, self).__init__()\n",
    "        self.data = results\n",
    "    \n",
    "    # path_listはpickle名\n",
    "    @classmethod\n",
    "    def read_pickle(cls, path_list):\n",
    "        df = pd.read_pickle(path_list[0])\n",
    "        for path in path_list[1:]:\n",
    "            df = update_data(df, pd.read_pickle(path))\n",
    "        return cls(df)\n",
    "    \n",
    "    @staticmethod\n",
    "    def scrape(race_id_list, pre_race_results={}):\n",
    "        race_results = pre_race_results\n",
    "        for race_id in tqdm(race_id_list):\n",
    "            if race_id in race_results.key():\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                time.sleep(1)\n",
    "                url = \"https://db.netkeiba.com/race/\" + race_id\n",
    "                df = pd.read_html(url)[0]\n",
    "                html = requests.get(url)\n",
    "                html.encode = \"EUC-JP\"\n",
    "                soup = BeautifulSoup(html.text, \"html.parser\")\n",
    "                \n",
    "                texts = (\n",
    "                    soup.find(\"div\", attrs={\"class\" : \"data_intro\"}).find_all(\"p\")[0].tesxt\n",
    "                    + soup.find(\"div\", attrs={\"class\" : \"data_intro\"}).find_all(\"p\")[1].tesxt\n",
    "                )\n",
    "                info = re.findall(r\"\\w+\", texts)\n",
    "                for text in info:\n",
    "                    if text in [\"芝\", \"ダート\"]:\n",
    "                        df[\"race_type\"] = [text] * len(df)\n",
    "                    if \"障\" in text:\n",
    "                        df[\"race_type\"] = [\"障害\"] * len(df)\n",
    "                    if \"m\" in text:\n",
    "                        df[\"course_len\"] = [int(re.findall(r\"\\d+\", text)[0])] * len(df)\n",
    "                    if text in [\"良\", \"稍重\", \"稍\", \"重\", \"不良\"]:\n",
    "                        df[\"ground_state\"] = [text] * len(df)\n",
    "                    if text in [\"曇\", \"晴\", \"雨\", \"小雨\", \"小雪\", \"雪\"]:\n",
    "                        df[\"weather\"] = [text] * len(df)\n",
    "                    if \"年\" in text:\n",
    "                        df[\"date\"] = [text] * len(df)\n",
    "                        \n",
    "                #馬ID、騎手IDをスクレイピング\n",
    "                horse_id_list = []\n",
    "                horse_a_list = soup.find(\"table\", attrs={\"summary\": \"レース結果\"}).find_all(\n",
    "                    \"a\", attrs={\"href\": re.compile(\"^/horse\")}\n",
    "                )\n",
    "                for a in horse_a_list:\n",
    "                    horse_id = re.findall(r\"\\d+\", a[\"href\"])\n",
    "                    horse_id_list.append(horse_id[0])\n",
    "                jockey_id_list = []\n",
    "                jockey_a_list = soup.find(\"table\", attrs={\"summary\": \"レース結果\"}).find_all(\n",
    "                    \"a\", attrs={\"href\": re.compile(\"^/jockey\")}\n",
    "                )\n",
    "                for a in jockey_a_list:\n",
    "                    jockey_id = re.findall(r\"\\d+\", a[\"href\"])\n",
    "                    jockey_id_list.append(jockey_id[0])\n",
    "                df[\"horse_id\"] = horse_id_list\n",
    "                df[\"jockey_id\"] = jockey_id_list\n",
    "\n",
    "                #インデックスをrace_idにする\n",
    "                df.index = [race_id] * len(df)\n",
    "                \n",
    "                race_results[race_id] = df \n",
    "                \n",
    "            except IndexError:\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                break\n",
    "            except:\n",
    "                break\n",
    "        return race_results\n",
    "        # 一度dataframe型に直さずに出力を返す        \n",
    "        #return race_results\n",
    "        \n",
    "    def to_data_frame(race_results):\n",
    "        race_results_df = pd.concat([race_results[key] for key in race_results])\n",
    "\n",
    "        return race_results_df\n",
    "        \n",
    "        \n",
    "        \n",
    "    # to_dataframe関数で出力後にdataframe型に変換が可能            \n",
    "    #def to_dataframe(race_results):\n",
    "        #race_results_df = pd.concat([race_results[key] for key in race_results])\n",
    "        \n",
    "        #r.data_rr = race_results_df                    \n",
    "                \n",
    "    # regressionをtrueにすることでsecond,着順が表示され回帰が行える。\n",
    "    def preprocessing(self, regression=False, ranking=False):\n",
    "        df = self.data.copy()\n",
    "\n",
    "        # 着順に数字以外の文字列が含まれているものを取り除く\n",
    "        df['着順'] = pd.to_numeric(df['着順'], errors='coerce')\n",
    "        df.dropna(subset=['着順'], inplace=True)\n",
    "        df['着順'] = df['着順'].astype(int)\n",
    "        df['rank'] = df['着順'].map(lambda x: 1 if x < 4 else 0)\n",
    "\n",
    "        # 性齢を性と年齢に分ける\n",
    "        df[\"性\"] = df[\"性齢\"].map(lambda x: str(x)[0])\n",
    "        df[\"年齢\"] = df[\"性齢\"].map(lambda x: str(x)[1:]).astype(int)\n",
    "\n",
    "        # 馬体重を体重と体重変化に分ける (馬体重修正するかも)\n",
    "        df[\"体重\"] = df[\"馬体重\"].str.split(\"(\", expand=True)[0].astype(int)\n",
    "        df[\"体重変化\"] = df[\"馬体重\"]\\\n",
    "            .str.split(\"(\", expand=True)[1].replace(\"前計不\", \"0\").str[:-1].astype(dtype = int)\n",
    "\n",
    "        # データをint, floatに変換\n",
    "        df[\"単勝\"] = df[\"単勝\"].astype(float)\n",
    "        df['course_len'] = df['course_len'].astype(float) // 100\n",
    "\n",
    "        # 不要な列を削除\n",
    "        #回帰子を作るために一時的に着順,タイムの列を削除しない。\n",
    "        #df.drop([\"タイム\", \"着差\", \"調教師\", \"性齢\", \"馬体重\",\"馬名\",\"騎手\",\"人気\",\"着順\"], axis=1, inplace=True)\n",
    "        df.drop([\"着差\", \"調教師\", \"性齢\", \"馬体重\",\"馬名\",\"騎手\",\"人気\",\"cource_len\"], axis=1, inplace=True)\n",
    "\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"], format=\"%Y年%m月%d日\")\n",
    "        \n",
    "        df[\"タイム\"].fillna(\"0\", inplace=True)\n",
    "        df[\"a\"] = df[\"タイム\"].map(lambda x:re.sub(r\"\\D\", \"\", x)).astype(str)\n",
    "        df[\"second\"] = df[\"a\"].map(lambda x: 0 if x==\"0\" \\\n",
    "        else (int(x[0]) * 60) + int(x[1:3]) + int(x[1:])/10).astype(float)\n",
    "        df.drop(\"a\", axis=1 ,inplace=True)\n",
    "        df.drop([\"タイム\"],axis=1, inplace=True)\n",
    "        \n",
    "        df[\"rls\"] = df[\"second\"]\\\n",
    "        .map(lambda x: np.sqrt(np.log(x)))\n",
    "        \n",
    "        df[\"ranking\"] = df[\"着順\"].map(lambda x: x if x==1 else\\\n",
    "            (x if x==2 else(x if x==3 else(x if x==4 else(x if x==5 else 0)))))\n",
    "        \n",
    "        df['開催'] = df.index.map(lambda x: str(x)[4:6])\n",
    "        \n",
    "        df[\"n_horses\"] = df.index.map(df.index.value_counts())\n",
    "        \n",
    "        if regression == True:\n",
    "            self.data_p = df\n",
    "        else:\n",
    "            self.data_p = df.drop([\"second\",\"着順\",\"rls\"],axis=1)\n",
    "            \n",
    "        if ranking == True:\n",
    "            self.data_p = df\n",
    "        else:\n",
    "            self.data_p = df.drop([\"ranking\"], axis=1)\n",
    "    \n",
    "    def process_categorical(self):\n",
    "        self.le_horse = LabelEncoder().fit(self.data_pe['horse_id'])\n",
    "        self.le_jockey = LabelEncoder().fit(self.data_pe['jockey_id'])\n",
    "        super().process_categorical(self.le_horse, self.le_jockey, self.data_pe)\n",
    "  \n",
    "    \n",
    "# ShutubaTable class        \n",
    "class ShutubaTable(DataProcessor):\n",
    "    def __init__(self, shutuba_tables):\n",
    "        super(ShutubaTable, self).__init__()\n",
    "        self.data = shutuba_tables\n",
    "        \n",
    "    @classmethod    \n",
    "    def scrape(cls, race_id_list, date):\n",
    "        data = pd.DataFrame()\n",
    "        for race_id in tqdm(race_id_list):\n",
    "            \n",
    "            url = 'https://race.netkeiba.com/race/shutuba.html?race_id=' + race_id\n",
    "            df = pd.read_html(url)[0]\n",
    "            df = df.T.reset_index(level=0, drop=True).T\n",
    "            \n",
    "            html = requests.get(url)\n",
    "            html.encoding = \"EUC-JP\"\n",
    "            soup = BeautifulSoup(html.text, \"html.parser\")\n",
    "            \n",
    "            texts = soup.find(\"div\", attrs={\"class\":\"RaceData01\"}).text\n",
    "            texts = re.findall(r\"\\w+\", texts)\n",
    "            for text in texts:\n",
    "                if 'm' in text:\n",
    "                    df['course_len'] = [int(re.findall(r'\\d+', text)[0])] * len(df)\n",
    "                if text in [\"曇\", \"晴\", \"雨\", \"小雨\", \"小雪\", \"雪\"]:\n",
    "                    df[\"weather\"] = [text] * len(df)\n",
    "                if text in [\"良\", \"稍重\", \"稍\", \"重\"]:\n",
    "                    df[\"ground_state\"] = [text] * len(df)\n",
    "                if '不' in text:\n",
    "                    df[\"ground_state\"] = ['不良'] * len(df)\n",
    "                if '芝' in text:\n",
    "                    df['race_type'] = ['芝'] * len(df)\n",
    "                if '障' in text:\n",
    "                    df['race_type'] = ['障害'] * len(df)\n",
    "                if 'ダ' in text:\n",
    "                    df['race_type'] = ['ダート'] * len(df)\n",
    "            df['date'] = [date] * len(df)\n",
    "            \n",
    "            # horse_id\n",
    "            horse_id_list = []\n",
    "            horse_td_list = soup.find_all(\"td\", attrs={'class': 'HorseInfo'})\n",
    "            for td in horse_td_list:\n",
    "                horse_id = re.findall(r'\\d+', td.find('a')['href'])[0]\n",
    "                horse_id_list.append(horse_id)\n",
    "            # jockey_id\n",
    "            jockey_id_list = []\n",
    "            jockey_td_list = soup.find_all(\"td\", attrs={'class': 'Jockey'})\n",
    "            for td in jockey_td_list:\n",
    "                jockey_id = re.findall(r'\\d+', td.find('a')['href'])[0]\n",
    "                jockey_id_list.append(jockey_id)\n",
    "            df['horse_id'] = horse_id_list\n",
    "            df['jockey_id'] = jockey_id_list\n",
    "\n",
    "            df.index = [race_id] * len(df)\n",
    "            data = data.append(df)\n",
    "            time.sleep(1)\n",
    "        return cls(data)\n",
    "\n",
    "    #disclosuer = Trueで馬体重が公開されていないデータでも予測が行える        \n",
    "    def preprocessing(self, disclosuer=False):\n",
    "        df = self.data.copy()\n",
    "        \n",
    "        df[\"性\"] = df[\"性齢\"].map(lambda x: str(x)[0])\n",
    "        df[\"年齢\"] = df[\"性齢\"].map(lambda x: str(x)[1:]).astype(int)\n",
    "\n",
    "        # 馬体重を体重と体重変化に分ける\n",
    "        if disclosuer == True:\n",
    "            df[\"体重\"] = 470\n",
    "            df[\"体重変化\"] = 0\n",
    "        else:\n",
    "            df = df[df[\"馬体重(増減)\"] != '--']\n",
    "            df[\"体重\"] = df[\"馬体重(増減)\"].str.split(\"(\", expand=True)[0].astype(int)\n",
    "\n",
    "            df[\"体重変化\"] = df[\"馬体重(増減)\"].str.split(\"(\", expand=True)[1].replace(\"前計不)\", \"0)\").str[:-1].astype(dtype = int)\n",
    "            \n",
    "        \n",
    "        #df[\"体重変化\"] = df[\"馬体重(増減)\"].str.split(\"(\", expand=True)[1]\n",
    "        #df[\"体重変化\"] = df[\"体重変化\"].replace(\"前計不)\", \"0)\")\n",
    "        #df[\"体重変化\"] = df[\"体重変化\"].str[:-1].astype(int)\n",
    "        \n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "        \n",
    "        df['枠'] = df['枠'].astype(int)\n",
    "        df['馬番'] = df['馬番'].astype(int)\n",
    "        df['斤量'] = df['斤量'].astype(int)\n",
    "        \n",
    "        df[\"開催\"] = df.index.map(lambda x:str(x)[4:6])\n",
    "        \n",
    "        df[\"n_horses\"] = df.index.map(df.index.value_counts())\n",
    "\n",
    "        # 不要な列を削除\n",
    "        df = df[['枠', '馬番', '斤量', 'course_len', 'weather','race_type',\n",
    "        'ground_state', 'date', 'horse_id', 'jockey_id', '性', '年齢',\n",
    "        '体重', '体重変化',\"開催\",\"n_horses\"]]\n",
    "        \n",
    "        self.data_p = df.rename(columns={'枠': '枠番'})\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d84503-f054-4dbe-b62f-6cb1d748b70d",
   "metadata": {},
   "source": [
    "horse_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af4c3add-4691-4ab5-8978-d0a1f8ae7b03",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Horse_Results:\n",
    "    def __init__(self, horse_results):\n",
    "        self.horse_results = horse_results[['日付','着順','賞金','着差','通過','開催','距離']]\n",
    "        self.preprocessing()\n",
    "        #self.horse_results.rename(columns={'着順':'着順_ave','賞金':'賞金_ave'}, inplace=True)\n",
    "    \n",
    "    # path_listはHorse_Results.pickle名\n",
    "    @classmethod\n",
    "    def read_pickle(cls, path_list):\n",
    "        df = pd.concat([pd.read_pickle(path) for path in path_list])\n",
    "        return cls(df)\n",
    "    # 使い方\n",
    "    # Horse_Results.read_pickle([pickle名])\n",
    "    \n",
    "    @staticmethod\n",
    "    def scrape(horse_id_list):\n",
    "        #horse_idをkeyにしてDataFrame型を格納\n",
    "        horse_results = {}\n",
    "        for horse_id in tqdm(horse_id_list):\n",
    "            try:\n",
    "                url = 'https://db.netkeiba.com/horse/' + horse_id\n",
    "                df = pd.read_html(url)[3]\n",
    "                #受賞歴がある馬の場合、3番目に受賞歴テーブルが来るため、4番目のデータを取得する\n",
    "                if df.columns[0]=='受賞歴':\n",
    "                    df = pd.read_html(url)[4]\n",
    "                df.index = [horse_id] * len(df)\n",
    "                horse_results[horse_id] = df\n",
    "                time.sleep(1)\n",
    "            except IndexError:\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                break\n",
    "            except:\n",
    "                break\n",
    "\n",
    "        #pd.DataFrame型にして一つのデータにまとめる        \n",
    "        horse_results_df = pd.concat([horse_results[key] for key in horse_results])\n",
    "\n",
    "        return horse_results_df\n",
    "        \n",
    "        \n",
    "    def preprocessing(self):\n",
    "        df = self.horse_results.copy()\n",
    "\n",
    "        # 着順に数字以外の文字列が含まれているものを取り除く\n",
    "        df['着順'] = pd.to_numeric(df['着順'], errors='coerce')\n",
    "        df.dropna(subset=['着順'], inplace=True)\n",
    "        df['着順'] = df['着順'].astype(int)\n",
    "\n",
    "        df[\"date\"] = pd.to_datetime(df[\"日付\"])\n",
    "        df.drop(['日付'], axis=1, inplace=True)\n",
    "        \n",
    "        #賞金のNaNを0で埋める\n",
    "        df['賞金'].fillna(0, inplace=True)\n",
    "        \n",
    "        #1着の着差を0にする\n",
    "        df['着差'] = df['着差'].map(lambda x: 0 if x<0 else x)\n",
    "        \n",
    "        #レース展開データ\n",
    "        #n=1: 最初のコーナー位置, n=4: 最終コーナー位置\n",
    "        def corner(x, n):\n",
    "            if type(x) != str:\n",
    "                return x\n",
    "            elif n==4:\n",
    "                return int(re.findall(r'\\d+', x)[-1])\n",
    "            elif n==1:\n",
    "                return int(re.findall(r'\\d+', x)[0])\n",
    "        df['first_corner'] = df['通過'].map(lambda x: corner(x, 1))\n",
    "        df['final_corner'] = df['通過'].map(lambda x: corner(x, 4))\n",
    "        \n",
    "        df['final_to_rank'] = df['final_corner'] - df['着順']\n",
    "        df['first_to_rank'] = df['first_corner'] - df['着順']\n",
    "        df['first_to_final'] = df['first_corner'] - df['final_corner']\n",
    "        \n",
    "        #開催場所\n",
    "        df['開催'] = df['開催'].str.extract(r'(\\D+)')[0].map(place_dict).fillna('11')\n",
    "        #race_type\n",
    "        df['race_type'] = df['距離'].str.extract(r'(\\D+)')[0].map(race_type_dict)\n",
    "        #距離\n",
    "        df['course_len'] = df['距離'].str.extract(r'(\\d+)').astype(int) // 100\n",
    "        df.drop(['距離'], axis=1, inplace=True)\n",
    "        \n",
    "        #インデックス名を与える\n",
    "        df.index.name = 'horse_id'\n",
    "    \n",
    "        self.horse_results = df\n",
    "        self.target_list = ['着順', '賞金', '着差', 'first_corner',\n",
    "                            'first_to_rank', 'first_to_final','final_to_rank']\n",
    "        \n",
    "        \n",
    "    def average(self, horse_id_list, date, n_samples='all'):\n",
    "        target_df = self.horse_results.loc[horse_id_list]\n",
    "        \n",
    "        #過去何走分取り出すか指定\n",
    "        if n_samples == 'all':\n",
    "            filtered_df = target_df[target_df['date'] < date]\n",
    "        elif n_samples > 0:\n",
    "            filtered_df = target_df[target_df['date'] < date].\\\n",
    "                sort_values('date', ascending=False).groupby(level=0).head(n_samples)\n",
    "        else:\n",
    "            raise Exception('n_samples must be >0')\n",
    "          \n",
    "        self.average_dict = {}\n",
    "        self.average_dict['non_category'] = filtered_df.groupby(level=0)[self.target_list]\\\n",
    "            .mean().add_suffix('_{}R'.format(n_samples))\n",
    "        for column in ['course_len', 'race_type', '開催']:\n",
    "            self.average_dict[column] = filtered_df.groupby(['horse_id', column])\\\n",
    "                [self.target_list].mean().add_suffix('_{}_{}R'.format(column, n_samples))    \n",
    "    \n",
    "    def merge(self, results, date, n_samples='all'):\n",
    "        df = results[results['date']==date]\n",
    "        horse_id_list = df['horse_id']\n",
    "        self.average(horse_id_list, date, n_samples)\n",
    "        merged_df = df.merge(self.average_dict['non_category'], left_on='horse_id',\n",
    "                             right_index=True, how='left')\n",
    "        for column in ['course_len','race_type', '開催']:\n",
    "            merged_df = merged_df.merge(self.average_dict[column], \n",
    "                                        left_on=['horse_id', column],\n",
    "                                        right_index=True, how='left')\n",
    "        return merged_df\n",
    "    \n",
    "    def merge_all(self, results, n_samples='all'):\n",
    "        date_list = results['date'].unique()\n",
    "        merged_df = pd.concat(\n",
    "            [self.merge(results, date, n_samples) for date in tqdm(date_list)]\n",
    "        )\n",
    "        return merged_df\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73d3480-e77d-4197-8799-91e10aa97886",
   "metadata": {},
   "source": [
    "return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86c06641-a186-42c0-bfb7-17d3fe9e166a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Return:\n",
    "    def __init__(self, return_tables):\n",
    "        self.return_tables = return_tables\n",
    "    \n",
    "    # path_listはpathではなく保存名で良い\n",
    "    @classmethod\n",
    "    def read_pickle(cls, path_list):\n",
    "        df = pd.concat([pd.read_pickle(path) for path in path_list])\n",
    "        return cls(df)\n",
    "        \n",
    "    @staticmethod\n",
    "    def scrape(race_id_list):\n",
    "        return_tables = {}\n",
    "        for race_id in tqdm(race_id_list):\n",
    "            try:\n",
    "                url = \"https://db.netkeiba.com/race/\" + race_id\n",
    "\n",
    "                #普通にスクレイピングすると複勝やワイドなどが区切られないで繋がってしまう。\n",
    "                #そのため、改行コードを文字列brに変換して後でsplitする\n",
    "                f = urlopen(url)\n",
    "                html = f.read()\n",
    "                html = html.replace(b'<br />', b'br')\n",
    "                dfs = pd.read_html(html)\n",
    "\n",
    "                #dfsの1番目に単勝〜馬連、2番目にワイド〜三連単がある\n",
    "                df = pd.concat([dfs[1], dfs[2]])\n",
    "\n",
    "                df.index = [race_id] * len(df)\n",
    "                return_tables[race_id] = df\n",
    "                time.sleep(0.7)\n",
    "            except IndexError:\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                break\n",
    "            except:\n",
    "                break\n",
    "\n",
    "        #pd.DataFrame型にして一つのデータにまとめる\n",
    "        return_tables_df = pd.concat([return_tables[key] for key in return_tables])\n",
    "        return return_tables_df\n",
    "    \n",
    "    @property\n",
    "    def sanrenpuku(self):\n",
    "        sanrenpuku = self.return_tables[self.return_tables[0] == \"三連複\"][[1,2]]\n",
    "        wins = sanrenpuku[1].str.split('-', expand=True)[[0,1,2]].add_prefix('wins_')\n",
    "        return_ = sanrenpuku[2].rename('return')\n",
    "        df = pd.concat([wins, return_], axis=1)\n",
    "        return df.apply(lambda x:pd.to_numeric(x.str.replace(',',''), errors='coerce'))\n",
    "    \n",
    "    @property\n",
    "    def sanrentan(self):\n",
    "        sanrentan = self.return_tables[self.return_tables[0] == \"三連単\"][[1,2]]\n",
    "        wins = sanrentan[1].str.split('→', expand=True)[[0,1,2]].add_prefix('wins_')\n",
    "        return_ = sanrentan[2].rename('return')\n",
    "        df = pd.concat([wins, return_], axis=1)\n",
    "        return df.apply(lambda x: pd.to_numeric(x.str.replace(',',''), errors='coerce'))\n",
    "    \n",
    "    @property #本来ならRetrun(return_tables).fukusho(retrun_tables)の形だが、\n",
    "    #Retrun(return_tables).fukushoで扱える\n",
    "    def fukusho(self):\n",
    "        fukusho = self.return_tables[self.return_tables[0] == '複勝'][[1,2]]\n",
    "        wins = fukusho[1].str.split('br', expand=True)[[0,1,2]]\n",
    "        wins.columns = ['win_0','win_1','win_2']\n",
    "        returns = fukusho[2].str.split('br', expand=True)[[0,1,2]]\n",
    "        returns.columns = ['return_0','return_1','return_2']\n",
    "        df = pd.concat([wins, returns], axis=1)\n",
    "        for column in df.columns:\n",
    "            df[column] = df[column].str.replace(',', \"\")\n",
    "        return df.fillna(0).astype(int)\n",
    "        \n",
    "    \n",
    "    @property\n",
    "    def wide(self):\n",
    "        wide = self.return_tables[self.return_tables[0] == \"ワイド\"][[1,2]]\n",
    "        wins = wide[1].str.split('br', expand=True)[[0,1,2]]\n",
    "        wins = wins.stack().str.split('-', expand=True).add_prefix('win_')\n",
    "        return_ = wide[2].str.split('br', expand=True)[[0,1,2]]\n",
    "        return_ = return_.stack().rename(\"return\")\n",
    "        df = pd.concat([wins, return_], axis=1)\n",
    "        return df.apply(lambda x: pd.to_numeric(x.str.replace(\",\",\"\"),errors='coerce'))\n",
    "    \n",
    "    @property #単勝に対して予測を行う\n",
    "    def tansho(self):\n",
    "        tansho = self.return_tables[self.return_tables[0] == '単勝'][[1,2]]\n",
    "        tansho.columns = ['win','return']\n",
    "        \n",
    "        for column in tansho.columns:\n",
    "            tansho[column] = pd.to_numeric(tansho[column], errors='coerce')\n",
    "        return tansho\n",
    "    \n",
    "    @property\n",
    "    def umaren(self):\n",
    "        umaren = self.return_tables[self.return_tables[0] == \"馬連\"][[1,2]]\n",
    "        wins = umaren[1].str.split('-', expand=True)[[0,1]].add_prefix(\"win_\")\n",
    "        #wins.columns = ([\"win_1\",\"win_2\"])#.add_prefix(\"win_\")\n",
    "        return_ = umaren[2].rename('return')\n",
    "        df = pd.concat([wins, return_], axis=1)\n",
    "        return df.apply(lambda x: pd.to_numeric(x, errors=\"coerce\"))\n",
    "    \n",
    "    @property\n",
    "    def umatan(self):\n",
    "        umatan = self.return_tables[self.return_tables[0] == '馬単'][[1,2]]\n",
    "        wins = umatan[1].str.split(\"→\", expand=True)[[0,1]].add_prefix(\"win_\")\n",
    "        return_ = umatan[2].rename('return')\n",
    "        df = pd.concat([wins, return_], axis=1)\n",
    "        return df.apply(lambda x: pd.to_numeric(x, errors=\"coerce\"))\n",
    "        \n",
    "        #for column in umaren.columns:\n",
    "            #umaren[column] = pd.to_numeric(umaren[column], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4a7ca5-7c0f-4b85-ac83-e3327b5253e6",
   "metadata": {},
   "source": [
    "modeleva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62e70826-21cb-4e26-8f2b-6a0915b2ea8f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#このクラス内において、第一引数にあたるxにはX_testのようなテストデータを入れる(単勝項目有)\n",
    "# return_tables_path = pickle_path\n",
    "class ModelEvaluator:\n",
    "    \n",
    "    def __init__(self, model, return_tables_list):\n",
    "        self.model = model\n",
    "        self.rt = Return.read_pickle(return_tables_list)\n",
    "        self.fukusho = self.rt.fukusho\n",
    "        self.tansho = self.rt.tansho\n",
    "        self.umaren = self.rt.umaren\n",
    "        self.umatan = self.rt.umatan\n",
    "        self.wide = self.rt.wide\n",
    "        self.sanrentan = self.rt.sanrentan\n",
    "        self.sanrenpuku = self.rt.sanrenpuku\n",
    "        #self.std = std\n",
    "\n",
    "    #3着以内に入る確率を予測、表示\n",
    "    #X = Objective Variable type\n",
    "    #引数train 項目に\"単勝\"があればdropする\n",
    "    #引数std 標準偏差の計算を行う\n",
    "    #引数minmax 出力された値のスケーリングを行う\n",
    "    def predict_proba(self, X, train=True, std=True, minmax=False):\n",
    "        #相対評価工程\n",
    "        if train:\n",
    "            proba = pd.Series(self.model.predict_proba(X.drop([\"単勝\"], axis=1))[:,1], index=X.index)\n",
    "        else:\n",
    "            proba = pd.Series(self.model.predict_proba(X, axis=1)[:,1], index=X.index)\n",
    "        #proba = pd.Series(self.model.predict_proba(X)[:,1], index=X.index)\n",
    "        if std:\n",
    "            standerd_scaler = lambda x: (x - x.mean()) / x.std()\n",
    "            proba = proba.groupby(level=0).transform(standerd_scaler)\n",
    "            \n",
    "        #min-maxスケーリング\n",
    "        if minmax:\n",
    "            proba = (proba - proba.min()) / (proba.max() - proba.min())\n",
    "        return proba \n",
    "    \n",
    "    #閾値(threshold)を設定する　デフォルト0.6\n",
    "    #predict_probaで確率がthreshold以上であれば1を出力(1=賭ける)\n",
    "    def predict(self, X, threshold=0.6):\n",
    "        y_pred = self.predict_proba(X)\n",
    "        self.proba = y_pred\n",
    "        return [0 if p<threshold else 1 for p in y_pred]\n",
    "        \n",
    "    #auc曲線のスコアを求める\n",
    "    def roc_auc_score(self, y_test, X_test):\n",
    "        return roc_auc_score(y_test, lgb_clf.predict_proba(X_test.drop([\"単勝\"], axis=1))[:, 1])\n",
    "    \n",
    "    #各成分の特徴量の強さの表示 デフォルト20\n",
    "    def feature_importance(self, X, n_display=20):\n",
    "        importances = pd.DataFrame({\"features\":X.columns, \n",
    "                                  \"importance\":self.model.feature_importances_})\n",
    "        return importances.sort_values('importance', ascending=False)[:n_display]\n",
    "    \n",
    "    #閾値を通して1と判定されたものだけをpred_tableとして出力する\n",
    "    def pred_table(self, X, threshold=0.6, bet_only = True):\n",
    "        pred_table = X.copy()[['馬番',\"単勝\"]]\n",
    "        pred_table['pred'] = self.predict(X, threshold)\n",
    "        pred_table[\"score\"] = self.proba\n",
    "        return pred_table[pred_table[\"pred\"] == 1]\n",
    "  \n",
    "    # umabanはint型で入力する必要がある\n",
    "    def bet(self, race_id, kind, umaban, amount):\n",
    "        if kind == \"tansho\":\n",
    "            rt_a = self.tansho.loc[race_id]\n",
    "            return_ = (rt_a['win'] == umaban) * amount/100 * rt_a['return']\n",
    "        elif kind == \"fukusho\":\n",
    "            rt_a = self.fukusho.loc[race_id]\n",
    "            return_ = ((rt_a[[\"win_0\",\"win_1\",\"win_2\"]] == umaban).values * \\\n",
    "            rt_a[['return_0',\"return_1\",\"return_2\"]]).sum() * amount/100\n",
    "        elif kind == \"umaren\":\n",
    "            rt_a = self.umaren.loc[race_id]\n",
    "            return_ = (set(rt_a[[\"win_0\",\"win_1\"]]) == set(umaban)) * rt_a[\"return\"] *\\\n",
    "            amount/100\n",
    "        elif kind == \"umatan\":\n",
    "            rt_a = self.umatan.loc[race_id]\n",
    "            return_ = (list(rt_a[[\"win_0\",\"win_1\"]]) == list(umaban)) * rt_a[\"return\"] *\\\n",
    "            amount/100\n",
    "        elif kind == \"wide\":\n",
    "            rt_a = self.wide.loc[race_id]\n",
    "            return_ = (rt_a[[\"win_0\",\"win_1\"]].apply(lambda x:set(x)==set(umaban),axis=1)) *\\\n",
    "            rt_a[\"return\"] / 100 * amount\n",
    "        elif kind == \"sanrentan\":\n",
    "            rt_a = self.sanrentan.loc[race_id]\n",
    "            return_ = (list(rt_a[[\"wins_0\",\"wins_1\",\"wins_2\"]])==list(umaban))*\\\n",
    "            rt_a[\"return\"] / 100 * amount \n",
    "        elif kind == 'sanrenpuku':\n",
    "            rt_a = self.sanrenpuku.loc[race_id]\n",
    "            return_ = (set(rt_a[[\"wins_0\",\"wins_1\",\"wins_2\"]])==set(umaban))*\\\n",
    "            rt_a[\"return\"]/100 * amount\n",
    "        elif not (return_ >= 0):\n",
    "            return_ = amount\n",
    "        return return_\n",
    "                \n",
    "\n",
    "    #items=True　にすることで、項目名の確認が可能になる。\n",
    "    #ただし、Trueの状態では、gain関数に利用することができないのでFalseの必要がある  \n",
    "    def fukusho_return(self, X, threshold=0.6, items=False):\n",
    "        pred_table = self.pred_table(X, threshold)\n",
    "        n_bets = len(pred_table)\n",
    "        return_list = []\n",
    "        for race_id, preds in pred_table.groupby(level=0):\n",
    "            return_list.append(np.sum([\\\n",
    "                self.bet(race_id,\"fukusho\",umaban,1) for umaban in preds[\"馬番\"]\\\n",
    "                                      ]))\n",
    "        return_rate = np.sum(return_list) / n_bets\n",
    "        std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "        n_hits = np.sum([x>0 for x in return_list])\n",
    "        \n",
    "        if items == True:    \n",
    "            return {\"n_bets\":n_bets, \"return_rate\":return_rate, \"n_hits\":n_hits, \"std\":std}\n",
    "        else:\n",
    "            return n_bets, return_rate, n_hits, std\n",
    "    \n",
    "    def tansho_return(self, X, threshold=0.6, items=False):\n",
    "        pred_table = self.pred_table(X, threshold)\n",
    "        self.sample = pred_table\n",
    "        n_bets = len(pred_table)\n",
    "        \n",
    "        return_list = []\n",
    "        for race_id, preds in pred_table.groupby(level=0):\n",
    "            return_list.append(\n",
    "                np.sum([self.bet(race_id,\"tansho\",umaban,1) for umaban in preds[\"馬番\"]])\n",
    "            )\n",
    "        std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "        \n",
    "        n_hits = np.sum([x>0 for x in return_list])\n",
    "        return_rate = np.sum(return_list) / n_bets\n",
    "        if items == True:\n",
    "            return {\"n_bets\":n_bets, \"return_rate\":return_rate, \"n_hits\":n_hits, \"std\":std}\n",
    "        else:\n",
    "            return n_bets, return_rate, n_hits, std     \n",
    " \n",
    "    def tansho_return_proper(self, X, threshold=0.6, items=False):\n",
    "        pred_table = self.pred_table(X, threshold)\n",
    "        n_bets = len(pred_table)\n",
    "        return_list = []\n",
    "        for race_id, preds in pred_table.groupby(level=0):\n",
    "            return_list.append(\n",
    "                np.sum(preds.apply(lambda x:self.bet(\n",
    "                race_id, \"tansho\", x[\"馬番\"], 1/x[\"単勝\"]), axis=1)))\n",
    "        bet_money = (1 / pred_table[\"単勝\"]).sum()\n",
    "        std = np.std(return_list) * np.sqrt(len(return_list)) / bet_money\n",
    "        n_hits = np.sum([x>0 for x in return_list])\n",
    "        return_rate = np.sum(return_list) / bet_money\n",
    "        if items == True:\n",
    "            return {\"n_bets\":n_bets, \"return_rate\":return_rate, \"n_hits\":n_hits, \"std\":std}\n",
    "        else:\n",
    "            return n_bets, return_rate, n_hits, std\n",
    "\n",
    "    \n",
    "    def umaren_box(self, X, threshold=0.6, n_aite=5, items=False):\n",
    "        pred_table = self.pred_table(X, threshold)\n",
    "        n_bets = 0\n",
    "        return_list = []\n",
    "        \n",
    "        for race_id, preds in pred_table.groupby(level=0):\n",
    "            return_ = 0\n",
    "            preds_jiku = preds.query('pred == 1')\n",
    "            if len(preds_jiku) == 1:\n",
    "                continue\n",
    "            elif len(preds_jiku) >= 2:\n",
    "                for umaban in combinations(preds_jiku[\"馬番\"], 2):\n",
    "                    return_ += self.bet(race_id, \"umaren\", umaban, 1)\n",
    "                    n_bets += 1\n",
    "                return_list.append(return_)\n",
    "                \n",
    "        std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "        n_hits = np.sum([x>0 for x in return_list])\n",
    "        return_rate = np.sum(return_list) / n_bets\n",
    "        if items == True:    \n",
    "            return {\"n_bets\":n_bets, \"return_rate\":return_rate, \"n_hits\":n_hits, \"std\":std}\n",
    "        else:\n",
    "            return n_bets, return_rate, n_hits, std\n",
    "\n",
    "    \n",
    "    def umatan_box(self, X, threshold=0.6, n_aite=5, items=False):\n",
    "        pred_table = self.pred_table(X, threshold, bet_only=False)\n",
    "        n_bets = 0\n",
    "        return_list = []\n",
    "        for race_id, preds in pred_table.groupby(level=0):\n",
    "            return_ = 0\n",
    "            preds_jiku = preds.query(\"pred == 1\")\n",
    "            if len(preds_jiku) == 1:\n",
    "                continue\n",
    "            elif len(preds_jiku) >= 2:\n",
    "                for umaban in permutations(preds_jiku[\"馬番\"], 2):\n",
    "                    return_ += self.bet(race_id, \"umatan\", umaban, 1)\n",
    "                    n_bets += 1\n",
    "                return_list.append(return_)\n",
    "            \n",
    "        std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "        n_hits = np.sum([x>0 for x in return_list])\n",
    "        return_rate = np.sum(return_list) / n_bets            \n",
    "        if items == True:\n",
    "            return {\"n_bets\":n_bets, \"return_rate\":return_rate, \"n_hits\":n_hits, \"std\":std}\n",
    "        else:\n",
    "            return n_bets, return_rate, n_hits, std\n",
    "\n",
    "        \n",
    "    def wide_box(self, X, threshold=0.6, n_aite=5, items=False):\n",
    "        pred_table = self.pred_table(X, threshold, bet_only=False)\n",
    "        n_bets = 0\n",
    "            \n",
    "        return_list = []\n",
    "        for race_id, preds in pred_table.groupby(level=0):\n",
    "            return_ = 0\n",
    "            preds_jiku = preds.query(\"pred == 1\")\n",
    "            if len(preds_jiku) == 1:\n",
    "                continue\n",
    "            elif len(preds_jiku) >= 2:\n",
    "                for umaban in combinations(presd_jiku[\"馬番\"], 2):\n",
    "                    return_ += self.bet(race_id, \"wide\", umaban, 1)\n",
    "                    n_bets += 1\n",
    "                return_list.append(return_)\n",
    "                    \n",
    "        std = np.sum(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "        n_hits = np.sum([x>0 for x in return_list])\n",
    "        return_rate = np.sum(return_list) / n_bets\n",
    "        if items == True:\n",
    "            return {\"n_bets\":n_bets, \"return_rate\":return_rate, \"n_hits\":n_hits, \"std\":std}\n",
    "        else:\n",
    "            return n_bets, return_rate, n_hits, std\n",
    "            \n",
    "    def sanrentan_box(self, X, threshold=0.6, items=False):\n",
    "        pred_table = self.pred_table(X, threshold)\n",
    "        n_bets = 0\n",
    "            \n",
    "        return_list = []\n",
    "        for race_id, preds in pred_table.groupby(level=0):\n",
    "            return_ = 0\n",
    "            if len(prefs) < 3:\n",
    "                continue\n",
    "            else:\n",
    "                for umaban in permutations(preds[\"馬番\"], 3):\n",
    "                    return_ += self.bet(race_id, \"sanrentan\", umaban, 1)\n",
    "                    n_bets += 1\n",
    "                return_list.append(return_)\n",
    "        std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "                \n",
    "        n_hits = np.sum([x>0 for x in return_list])\n",
    "        return_rate = np.sum(return_list) / n_bets\n",
    "        if items == True:\n",
    "            return {\"n_bets\":n_bets, \"return_rate\":return_rate, \"n_hits\":n_hits, \"std\":std}\n",
    "        else:\n",
    "            return n_bets, return_rate, n_hits, std\n",
    "            \n",
    "    def sanrenpuku_box(self, X, threshold=0.6, items=False):\n",
    "        pred_table = self.pred_table(X, threshold)\n",
    "        n_bets = 0\n",
    "        return_list = []\n",
    "            \n",
    "        for race_id, preds in pred_table.groupbu(level=0):\n",
    "            return_ = 0\n",
    "            if len(preds) < 3:\n",
    "                continue\n",
    "            else:\n",
    "                for umaban in combinations(preds[\"馬番\"], 3):\n",
    "                    return_ += self.bet(race_id ,\"sanrenpuku\", umaban, 1)\n",
    "                    n_bets += 1\n",
    "                return_list.append(return_)\n",
    "        std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "        n_hits = np.sum([x>0 for x in return_list])\n",
    "        return_rate = np.sum(return_list) / n_bets\n",
    "        if items == True:\n",
    "            return {\"n_bets\":n_bets, \"return_rate\":return_rate, \"n_hits\":n_hits, \"std\":std}\n",
    "        else:\n",
    "            return n_bets, return_rate, n_hits, std\n",
    "        \n",
    "    def umaren_nagashi(self, X, threshold=0.6, n_aite=5, items=False):\n",
    "        pred_table = self.pred_table(X, threshold, bet_only=False)\n",
    "        n_bets = 0\n",
    "        return_lsit = []\n",
    "            \n",
    "        for race_id, preds in pred_table.groupbu(level=0):\n",
    "            return_ = 0\n",
    "            preds_ijku = preds.query(\"pred == 1\")\n",
    "            if len(preds_jiku) == 1:\n",
    "                preds_aite = preds.sort_values(\"score\", ascending=False)\\\n",
    "                .iloc[1:(n_aite+1)][\"馬番\"]\n",
    "                return_ = preds_aite.map(\n",
    "                race_id, \"umaban\", [preds_jiku[\"馬番\"].values[0], x], 1).sum()\n",
    "                n_bets += n_aite\n",
    "                return_list.append(return_)\n",
    "            elif len(preds_jiku) >= 2:\n",
    "                for umaban in combinations(preds_jiku[\"馬番\"], 2):\n",
    "                    return_ += self.bet(race_id, \"umaban\", umaban, 1)\n",
    "                    n_bets += 1\n",
    "                return_list.append(return_)\n",
    "        std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "        n_hits = np.sum([x>0 for x in return_list])    \n",
    "        return_rate = np.sum(return_list) / n_bets \n",
    "        if items == True:\n",
    "            return {\"n_bets\":n_bets, \"return_rate\":return_rate, \"n_hits\":n_hits, \"std\":std}\n",
    "        else:\n",
    "            return n_bets, return_rate, n_hits, std\n",
    "        \n",
    "    def umatan_nagashi(self, X, threshold=0.6, n_aite=5, items=False):\n",
    "        pred_table = self.pred_table(X, threshold, bet_only=False)\n",
    "        n_bets = 0\n",
    "        return_lsit = []\n",
    "        for race_id, preds in pred_table.groupby(level=0):\n",
    "            return_ = 0\n",
    "            preds_jiku = preds.query(\"pred == 1\")\n",
    "            if len(preds_jiku) == 1:\n",
    "                preds_aite = preds.sort_values(\"score\", ascending=False).\\\n",
    "                iloc[1: (n_aite+1)][\"馬番\"]\n",
    "                return_ = preds_aite.map(\n",
    "                lambda x: self.bet(race_id, \"umatan\", [preds_jiku[\"馬番\"].values[0], x], 1)).sum()\n",
    "                n_bets += n_aite\n",
    "            elif len(preds_jiku) >= 2:\n",
    "                for umaban in permutations(preds_jiku[\"馬番\"], 2):\n",
    "                    return_ += self.bet(race_id, \"umatan\", umaban, 1)\n",
    "                    n_bets += 1\n",
    "            return_list.append(return_)\n",
    "        std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "        n_hits = np.sum([x>0 for x in return_list])\n",
    "        return_rate = np.sum(return_list) / n_bets\n",
    "        if items == True:\n",
    "            return {\"n_bets\":n_bets, \"return_rate\":return_rate, \"n_hits\":n_hits, \"std\":std}\n",
    "        else:\n",
    "            return n_bets, return_rate, n_hits, std\n",
    "        \n",
    "    def wide_nagashi(self, X, threshold=0.6, n_aite=5, items=False):\n",
    "        pred_table = self.pred_table(X, threshpld, bet_only=False)\n",
    "        n_bets = 0\n",
    "        return_list = []\n",
    "        for race_id, preds in pred_table.groupby(level=0):\n",
    "            return_ = 0\n",
    "            preds_jiku = preds.query(\"pred == 1\")\n",
    "            if len(preds_jiku) == 1:\n",
    "                preds_aite = preds.sort_values(\"scoer\", ascending=False).iloc[1:(n_aite+1)][\"馬番\"]\n",
    "                return_ = preds_aite.map(lambda x: self.bet(race_id, \"wide\", [preds_jiku[\"馬番\"].values[0], x], 1)).sum()\n",
    "                n_bets += len(preds_aite)\n",
    "                return_list.append(return_)\n",
    "            elif len(preds_jiku) >= 2:\n",
    "                for umaban in combinations(preds_jiku[\"馬番\"], 2):\n",
    "                    return_ += self.bet(race_id, \"wide\", umaban, 1)\n",
    "                    n_bets += 1\n",
    "                return_list.append(return_)\n",
    "        std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "        n_hits = np.sum([x>0 for x in return_list])\n",
    "        return_rate = np.sum(return_list) / n_bets\n",
    "        if items == True:\n",
    "            return {\"n_bets\":n_bets, \"return_rate\":return_rate, \"n_hits\":n_hits, \"std\":std}\n",
    "        else:\n",
    "            return n_bets, return_rate, n_hits, std\n",
    "        \n",
    "    def sanrentan_nagshi(self, X, thresholf=1.5, n_aite=7, items=False):\n",
    "        pred_table = self.pred_table(X, thresholod, bet_only=False)\n",
    "        n_bets = 0\n",
    "        return_ = []\n",
    "        for race_id, preds in pred_table.groupbu(level=0):\n",
    "            preds_jiku = preds.query(\"pred == 1\")\n",
    "            if len(preds_jiku) == 1:\n",
    "                continue\n",
    "            elif len(preds_jiku) == 2:\n",
    "                preds_aite = preds.sort_values(\"score\", ascending=False).\\\n",
    "                iloc[2: (n_aite+2)][\"馬番\"]\n",
    "                return_ = preds_aite.map(lambda x: self.bet(race_id, \"sanrentan\",np.append\\\n",
    "                                                                (preds_jiku[\"馬番\"].values, x), 1)).sum()\n",
    "                n_bets += len(preds_aite)\n",
    "                return_list.append(return_)\n",
    "            elif len(preds_jiku) >= 3:\n",
    "                return_ = 0\n",
    "                for umaban in permutations(preds_jiku[\"馬番\"], 3):\n",
    "                    return_ += self.bet(race_id, \"sanrentan\", umaban, 1)\n",
    "                    n_bets += 1\n",
    "                return_list.append(return_)\n",
    "                \n",
    "        std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "        n_hits = np.sum([x>0 for x in return_list])\n",
    "        return_rate = np.sum(return_lsit) / n_bets\n",
    "        if items == True:\n",
    "            return {\"n_bets\":n_bets, \"return_rate\":return_rate, \"n_hits\":n_hits, \"std\":std}\n",
    "        else:\n",
    "            return n_bets, return_rate, n_hits, std\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ec4429-d2f5-43e6-8f70-4d38c809eb08",
   "metadata": {},
   "source": [
    "peds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "276cd3a9-502f-4316-806e-a12800b7b38f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Peds:\n",
    "    def __init__(self, peds):\n",
    "        self.peds = peds\n",
    "        self.peds_e = pd.DataFrame() #after label encoding and transforming into category\n",
    "    \n",
    "    def encode(self):\n",
    "        df = self.peds.copy()\n",
    "        for column in df.columns:\n",
    "            df[column] = LabelEncoder().fit_transform(df[column].fillna('Na'))\n",
    "        self.peds_e = df.astype('category')\n",
    "    \n",
    "    # Peds.read_pickle([\"pickle_path\"])\n",
    "    @classmethod\n",
    "    def read_pickle(cls, path_list):\n",
    "        df = pd.read_pickle(path_list[0])\n",
    "        for path in path_list[1:]:\n",
    "            df = update_data(df, pd.read_pickle(path))\n",
    "        return cls(df)\n",
    "        #df = pd.concat([pd.read_pickle(path) for path in path_list])\n",
    "        #return cls(df)\n",
    "    \n",
    "    @staticmethod\n",
    "    def scrape(horse_id_list):\n",
    "        peds_dict = {}\n",
    "        for horse_id in tqdm(horse_id_list):\n",
    "            try:\n",
    "                url = \"https://db.netkeiba.com/horse/ped/\" + horse_id\n",
    "                df = pd.read_html(url)[0]\n",
    "                \n",
    "                #重複を削除して1列のSeries型データに直す\n",
    "                generations = {}\n",
    "                for i in reversed(range(5)):\n",
    "                    generations[i] = df[i]\n",
    "                    df.drop([i], axis = 1, inplace = True)\n",
    "                    df = df.drop_duplicates()\n",
    "                ped = pd.concat([generations[i] for i in range(5)]).rename(horse_id)\n",
    "                \n",
    "                peds_dict[horse_id] = ped.reset_index(drop = True)\n",
    "                time.sleep(0.7)\n",
    "                \n",
    "            except IndexError:\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                break\n",
    "            except:\n",
    "                break\n",
    "        #return peds\n",
    "                \n",
    "        #列名をpeds_0, ..., peds_61にする\n",
    "        peds_df = pd.concat([peds_dict[key] for key in peds_dict], axis=1).T.add_prefix('peds_')\n",
    "    \n",
    "        return peds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9656df8d-4674-4925-9126-af9402ffe3ad",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a76c58235943444b8c24edd65cfb33b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/111 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73f7010b7ab94cf6936107f07c932bfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d09e33c60b0a451eadb2a4f43f998cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#過去レースデータの前処理\n",
    "r = Results(results_data)\n",
    "r.preprocessing(regression=True, ranking=False)\n",
    "#馬の過去レース情報の追加\n",
    "hr = Horse_Results.read_pickle([\"pickle_file/horse_results_19.pickle\",\n",
    "                   'pickle_file/horse_results_20.pickle',\n",
    "                   'pickle_file/horse_results_21.pickle'])\n",
    "r.merge_horse_results(hr)\n",
    "#馬の親データの追加、カテゴリデータとしてエンコード\n",
    "P = Peds(peds_data)\n",
    "P.encode()\n",
    "r.merge_peds(P.peds_e)\n",
    "#質的データのエンコード\n",
    "r.process_categorical()\n",
    "#テストデータ、訓練データ、学習データに分割\n",
    "train, test = split_data(r.data_c)\n",
    "train, valid = split_data(train)\n",
    "\n",
    "X_train = train.drop([\"rank\",\"date\",\"単勝\",\"second\",\"rls\",\"着順\",\"data\"],axis=1)\n",
    "y_train = train[\"rank\"]\n",
    "X_test = test.drop([\"rank\",\"date\",\"単勝\",\"second\",\"rls\",\"着順\",\"data\"],axis=1)\n",
    "y_test = test[\"rank\"]\n",
    "X_valid = valid.drop([\"rank\",\"date\",\"単勝\",\"second\",\"rls\",\"着順\",\"data\"],axis=1)\n",
    "y_valid = valid[\"rank\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd7ed693-f214-49cc-b0be-5510ceccc916",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#optunaによって出力されたハイパーパラメータ\n",
    "params = {\n",
    " 'objective': 'binary',\n",
    " 'random_state': 100,\n",
    " 'feature_pre_filter': False,\n",
    " 'lambda_l1': 9.490245203532942e-07,\n",
    " 'lambda_l2': 6.421168438428032,\n",
    " 'num_leaves': 36,\n",
    " 'feature_fraction': 0.4,\n",
    " 'bagging_fraction': 1.0,\n",
    " 'bagging_freq': 0,\n",
    " 'min_child_samples': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6b2cffd3-6ed5-48bd-bfe1-b220d70897fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.4,\n",
       "               feature_pre_filter=False, lambda_l1=9.490245203532942e-07,\n",
       "               lambda_l2=6.421168438428032, min_child_samples=5, num_leaves=36,\n",
       "               objective='binary', random_state=100)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#学習データをフィッティング\n",
    "lgb_clf = lgb.LGBMClassifier(**params)\n",
    "lgb_clf.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "613c1901-5db2-41fd-98c2-8092b54e80b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9892d11f7a742dc8535600aaa0c6d37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cae10b0c4b6d46dbb8400d9075ccfe60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27bac245593e4594b49619c75858aa2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deb6d97a155748c69015f7d01f31939a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>馬番</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202106050811</th>\n",
       "      <td>7</td>\n",
       "      <td>2.643638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202106050811</th>\n",
       "      <td>9</td>\n",
       "      <td>1.499066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202106050811</th>\n",
       "      <td>10</td>\n",
       "      <td>0.815996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202106050811</th>\n",
       "      <td>2</td>\n",
       "      <td>0.270560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202106050811</th>\n",
       "      <td>11</td>\n",
       "      <td>0.216243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202106050811</th>\n",
       "      <td>16</td>\n",
       "      <td>0.129985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202106050811</th>\n",
       "      <td>13</td>\n",
       "      <td>0.115631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202106050811</th>\n",
       "      <td>5</td>\n",
       "      <td>0.025744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202106050811</th>\n",
       "      <td>6</td>\n",
       "      <td>-0.203321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202106050811</th>\n",
       "      <td>12</td>\n",
       "      <td>-0.282550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202106050811</th>\n",
       "      <td>15</td>\n",
       "      <td>-0.567329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202106050811</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.706846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202106050811</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.738131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202106050811</th>\n",
       "      <td>8</td>\n",
       "      <td>-1.015391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202106050811</th>\n",
       "      <td>14</td>\n",
       "      <td>-1.074617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202106050811</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.128677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              馬番     score\n",
       "202106050811   7  2.643638\n",
       "202106050811   9  1.499066\n",
       "202106050811  10  0.815996\n",
       "202106050811   2  0.270560\n",
       "202106050811  11  0.216243\n",
       "202106050811  16  0.129985\n",
       "202106050811  13  0.115631\n",
       "202106050811   5  0.025744\n",
       "202106050811   6 -0.203321\n",
       "202106050811  12 -0.282550\n",
       "202106050811  15 -0.567329\n",
       "202106050811   3 -0.706846\n",
       "202106050811   1 -0.738131\n",
       "202106050811   8 -1.015391\n",
       "202106050811  14 -1.074617\n",
       "202106050811   4 -1.128677"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#予測を行うレースidを入力\n",
    "race_id = [\"202106050811\"]　#予測を行いたいレースIDを入力　2021年6月5日京都競馬場で行われる第11レース\n",
    "st = ShutubaTable.scrape(race_id, \"2021/12/26\")　\n",
    "\n",
    "#出馬テーブルの整形\n",
    "st.preprocessing()\n",
    "st.merge_horse_results(hr)\n",
    "st.merge_peds(P.peds_e)\n",
    "st.process_categorical(r.le_horse, r.le_jockey, r.data_pe)\n",
    "\n",
    "me = ModelEvaluator(lgb_clf,[\"pickle_file/Return_tables_all.pickle\"])\n",
    "\n",
    "#予測\n",
    "scores = me.predict_proba(st.data_c.drop(['date'], axis=1), train=False)\n",
    "pred = st.data_c[['馬番']].copy()\n",
    "pred['score'] = scores\n",
    "pred.loc['202106050811'].sort_values('score', ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad53b489-0df3-4bdf-86c2-a66847adf93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressionのFalseで特徴量を削除する\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
